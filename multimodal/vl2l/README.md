# MLPerf Inference Vision-language-to-language (VL2L) Reference Implementation

[Qwen3-VL-235B-A22B](https://github.com/QwenLM/Qwen3-VL/tree/4aae93c9fcca19d7cbca6b095d64f578d25ed75f)
is currently selected as the model for the VL2L benchmark.